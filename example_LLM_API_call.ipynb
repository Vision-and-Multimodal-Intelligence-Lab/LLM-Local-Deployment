{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"\"  # \n",
    "\n",
    "# PORT = 50000 # Llama-70B\n",
    "PORT = 50001  # Qwen-14B\n",
    "\n",
    "API_KEY = \"\"  # as registered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using OpenAI Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuralmagic/DeepSeek-R1-Distill-Qwen-14B-quantized.w4a16\n"
     ]
    }
   ],
   "source": [
    "%pip install openai\n",
    "\n",
    "import openai\n",
    "\n",
    "client = openai.Client(base_url=f\"http://{HOST}:{PORT}/v1\", api_key=API_KEY)\n",
    "model_name = client.models.list().data[0].id\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Reasoning ====\n",
      "I need to determine which number is larger between 9.11 and 9.8.\n",
      "\n",
      "First, I'll align the decimal places by writing 9.8 as 9.80.\n",
      "\n",
      "Next, I'll compare each corresponding digit starting from the left.\n",
      "\n",
      "Both numbers have 9 in the ones place, so I'll move to the tenths place.\n",
      "\n",
      "In the tenths place, 9.11 has a 1, while 9.80 has an 8.\n",
      "\n",
      "Since 1 is less than 8, 9.11 is smaller than 9.80.\n",
      "\n",
      "Therefore, 9.8 is the larger number.\n",
      "\n",
      "==== Output ====\n",
      "**Solution:**\n",
      "\n",
      "To determine which number is larger between **9.11** and **9.8**, follow these steps:\n",
      "\n",
      "1. **Align the Decimal Places:**\n",
      "   \n",
      "   \\[\n",
      "   \\begin{align*}\n",
      "   9.11 \\\\\n",
      "   9.80 \\quad (\\text{since } 9.8 = 9.80)\n",
      "   \\end{align*}\n",
      "   \\]\n",
      "\n",
      "2. **Compare the Numbers Digit by Digit:**\n",
      "\n",
      "   - **Ones Place:** Both numbers have **9**.\n",
      "   - **Tenths Place:** \n",
      "     - **9.11** has **1**.\n",
      "     - **9.80** has **8**.\n",
      "   \n",
      "   Since **1 < 8**, **9.11** is smaller than **9.80**.\n",
      "\n",
      "3. **Conclusion:**\n",
      "   \n",
      "   \\[\n",
      "   9.80 > 9.11\n",
      "   \\]\n",
      "\n",
      "   Therefore, **9.8** is the larger number.\n",
      "\n",
      "\\[\n",
      "\\boxed{9.8}\n",
      "\\]\n"
     ]
    }
   ],
   "source": [
    "message = \"Which one is larger, 9.11 or 9.8?\"\n",
    "\n",
    "response_non_stream = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },  # Optional, system prompts\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    "    stream=False,  # Non-streaming\n",
    ")\n",
    "\n",
    "print(\"==== Reasoning ====\")\n",
    "print(response_non_stream.choices[0].message.reasoning_content)\n",
    "\n",
    "print(\"==== Output ====\")\n",
    "print(response_non_stream.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Streaming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Reasoning ====\n",
      "To determine which number is larger between 9.11 and 9.8, I'll start by comparing their whole number parts.\n",
      "\n",
      "Both numbers have the same whole number part, which is 9.\n",
      "\n",
      "Since the whole numbers are equal, I'll move on to compare the decimal parts.\n",
      "\n",
      "In 9.11, the decimal part is 0.11, while in 9.8, it's 0.8.\n",
      "\n",
      "To make a fair comparison, I'll express 0.8 as 0.80.\n",
      "\n",
      "Now, comparing 0.11 and 0.80, it's clear that 0.80 is larger than 0.11.\n",
      "\n",
      "Therefore, 9.8 is the larger number.\n",
      "\n",
      "==== Output ====\n",
      "\n",
      "\n",
      "**Solution:**\n",
      "\n",
      "To determine which number is larger between **9.11** and **9.8**, follow these steps:\n",
      "\n",
      "1. **Compare the Whole Number Parts:**\n",
      "   - Both numbers have the same whole number part: **9**.\n",
      "   \n",
      "2. **Compare the Decimal Parts:**\n",
      "   - **9.11** has a decimal part of **0.11**.\n",
      "   - **9.8** can be written as **9.80**, which has a decimal part of **0.80**.\n",
      "\n",
      "3. **Determine Which Decimal is Larger:**\n",
      "   - **0.80** (from 9.80) is greater than **0.11** (from 9.11).\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Since the decimal part of **9.8** is larger than that of **9.11**, we can conclude that:\n",
      "\n",
      "\\[\n",
      "\\boxed{9.8 \\text{ is larger than } 9.11}\n",
      "\\]"
     ]
    }
   ],
   "source": [
    "response_stream = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },  # Optional, system prompts\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    "    stream=True,  # streaming\n",
    ")\n",
    "\n",
    "reasoning = \"\"\n",
    "output = \"\"\n",
    "content_start = False\n",
    "\n",
    "print(\"==== Reasoning ====\")\n",
    "for chunk in response_stream:\n",
    "    if chunk.choices[0].delta.content:\n",
    "        if not content_start:\n",
    "            content_start = True\n",
    "            print(\"\\n==== Output ====\")\n",
    "        print(chunk.choices[0].delta.content, end=\"\")\n",
    "        output += chunk.choices[0].delta.content\n",
    "    elif chunk.choices[0].delta.reasoning_content:\n",
    "        print(chunk.choices[0].delta.reasoning_content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple rounds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Round 1 ====\n",
      "==== Reasoning ====\n",
      "Okay, so I need to figure out the top three most common misconceptions about large language models. I'm not super familiar with this, but I'll try to think it through step by step.\n",
      "\n",
      "First, I should probably understand what large language models (LLMs) are. From what I know, they're AI systems that can process and generate human-like text. They're used in things like chatbots, translation, and even writing assistance. But I'm not entirely sure about all their capabilities and limitations.\n",
      "\n",
      "Now, the question is about misconceptions. Misconceptions are wrong beliefs that people have about something. So, I need to think about what people commonly think about LLMs that isn't accurate.\n",
      "\n",
      "One thing that comes to mind is that people might think these models are perfect and always give correct answers. But I remember reading somewhere that they can make mistakes or generate nonsensical answers. Maybe people assume they're 100% accurate, which isn't the case.\n",
      "\n",
      "Another thought is about how these models work. I think some people believe that LLMs understand the context and meaning behind the text, almost like a human. But I've heard that they actually work by recognizing patterns in data without truly understanding the content. So, they might seem to understand, but it's just surface-level.\n",
      "\n",
      "Then there's the issue of bias. I've heard that LLMs can be biased because they're trained on existing data, which might have biases from the real world. People might not realize that the outputs can reflect those biases, leading to unfair or incorrect conclusions.\n",
      "\n",
      "Wait, but I should make sure these are the top three. Let me think if there are others. Maybe the idea that they can handle all languages equally well? Or that they can explain their reasoning? I'm not sure if those are as common as the ones I thought of.\n",
      "\n",
      "I think the three I listed are pretty common. People overestimating their accuracy, misunderstanding how they process information, and not being aware of the biases. These seem to be the main points I've heard about.\n",
      "\n",
      "So, to summarize, the top three misconceptions would be:\n",
      "\n",
      "1. Believing that LLMs are infallible and always provide correct answers.\n",
      "2. Thinking that LLMs truly understand context and meaning, similar to humans.\n",
      "3. Ignoring the biases present in LLMs that can lead to unfair or incorrect outputs.\n",
      "\n",
      "I think that covers the main points. I should make sure to explain each clearly, maybe with examples or references to how LLMs actually function.\n",
      "\n",
      "==== Output ====\n",
      "The top three most common misconceptions about large language models (LLMs) are:\n",
      "\n",
      "1. **Infallibility**: Many people assume that LLMs are perfect and always provide correct answers. However, LLMs can make mistakes, generate nonsensical responses, and sometimes provide incorrect information. This is because they learn from data and can produce outputs that are not always accurate or reliable.\n",
      "\n",
      "2. **Understanding Context**: There's a belief that LLMs truly understand the context and meaning behind the text, akin to human comprehension. In reality, LLMs process information by recognizing patterns and statistical correlations in the data they are trained on. They don't have true understanding or consciousness, which can lead to superficial interactions.\n",
      "\n",
      "3. **Bias Awareness**: Some users are unaware that LLMs can exhibit biases present in their training data. These biases can lead to unfair or incorrect outputs, reinforcing stereotypes or making unfair judgments. It's crucial to be mindful of this when interpreting their responses.\n",
      "\n",
      "These misconceptions highlight the importance of understanding both the capabilities and limitations of LLMs.\n",
      "\n",
      "\n",
      "==== Round 2 ====\n",
      "==== Reasoning ====\n",
      "Alright, the user is asking how to address the misconceptions about large language models that I previously listed. They must be looking for practical ways to correct these misunderstandings. \n",
      "\n",
      "First, I need to consider who the user might be. They could be educators, developers, or anyone interested in AI. Their real need is probably to better communicate the true nature of LLMs, maybe to train others or improve their own interactions with these models.\n",
      "\n",
      "I should break down each misconception and provide clear, actionable solutions. For infallibility, emphasizing transparency and honesty is key. Maybe suggesting ways to highlight when the model isn't certain or pointing out potential errors.\n",
      "\n",
      "For the understanding context misconception, explaining how LLMs work in simple terms, like pattern recognition instead of actual comprehension, would help. Using analogies might make it clearer for non-experts.\n",
      "\n",
      "Regarding bias, it's important to discuss how biases manifest and ways to mitigate them. Providing resources or methods to detect and correct biased outputs would be useful.\n",
      "\n",
      "I should also think about broader strategies like education, transparency, and ethical guidelines. These can create a comprehensive approach to correcting these misconceptions. \n",
      "\n",
      "Overall, the response should be structured, clear, and offer both theoretical explanations and practical steps. This way, the user gets a well-rounded understanding of how to address each misconception effectively.\n",
      "\n",
      "==== Output ====\n",
      "Addressing and correcting misconceptions about large language models (LLMs) requires clear communication, education, and responsible use. Here are some strategies to help correct these misunderstandings:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Addressing the Misconception of \"Infallibility\" (LLMs being perfect or always correct):**\n",
      "- **Educate users about limitations**: Clearly communicate that LLMs are not perfect and can make mistakes, especially when dealing with ambiguous or complex queries. They rely on patterns in data and may generate nonsensical or incorrect responses.\n",
      "- **Encourage critical thinking**: Users should verify information provided by LLMs, especially when it comes to facts, decisions, or sensitive topics. They should cross-check with reliable sources or consult experts.\n",
      "- **Transparency in outputs**: Developers can design interfaces that highlight when the model is uncertain or provide disclaimers about the potential for errors in its responses.\n",
      "- **Iterative improvement**: Regularly update and refine the models to reduce errors and improve accuracy over time.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Clarifying the Misconception of \"Understanding Context\" (LLMs having human-like comprehension):**\n",
      "- **Explain how LLMs work**: Simplify the concept of how LLMs process text as patterns and statistical correlations, rather than true comprehension. For example, you can say, \"The model doesn't 'understand' what you're asking; it generates responses based on patterns in the data it was trained on.\"\n",
      "- **Use analogies**: Compare LLMs to tools like calculators or search engines—they process inputs in a specific way and produce outputs based on their programming, not consciousness or intent.\n",
      "- **Highlight limitations in nuance**: Users should be aware that LLMs may struggle with sarcasm, irony, or deeply contextual information that requires human-like reasoning.\n",
      "- **Encourage empathy and context-checking**: Users should question whether the model's response aligns with the intent of the query, especially in complex or subjective scenarios.\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Addressing the Misconception of \"Bias Awareness\" (LLMs being neutral or unbiased):**\n",
      "- **Raise awareness about bias in AI**: Educate users about how biases in training data can lead to biased or unfair outputs from LLMs. For example, if the training data contains stereotypes, the model may perpetuate them.\n",
      "- **Provide tools for bias mitigation**: Developers can build safeguards into LLMs, such as flagging potentially biased or harmful responses, or offering alternatives to reduce bias.\n",
      "- **Encourage diverse training data**: Strive to create more balanced and representative training datasets to reduce the risk of perpetuating biases.\n",
      "- **Foster accountability**: Users should be encouraged to report biased or harmful outputs, and developers should continuously monitor and improve the models to address these issues.\n",
      "\n",
      "---\n",
      "\n",
      "### **Broader Strategies to Correct Misconceptions:**\n",
      "1. **Public education and outreach**: Create accessible resources, tutorials, and workshops to explain how LLMs work and their limitations. This can help demystify the technology and reduce misunderstandings.\n",
      "2. **Transparency in AI development**: Make the inner workings of LLMs more accessible to the public, such as through explainable AI (XAI) techniques, so users can better understand how decisions are made.\n",
      "3. **Ethical guidelines and responsible AI practices**: Establish clear guidelines for the development and deployment of LLMs to ensure they are used ethically and responsibly.\n",
      "4. **Encourage dialogue**: Foster open discussions between developers, policymakers, and the public about the capabilities and limitations of LLMs to build a more informed user base.\n",
      "\n",
      "---\n",
      "\n",
      "By addressing these misconceptions through education, transparency, and responsible use, we can help users better understand and utilize LLMs while minimizing the risks of misapplying or over-relying on them.\n"
     ]
    }
   ],
   "source": [
    "message = \"What are the top 3 most common misconceptions about large language models?\"\n",
    "message2 = \"How can these misconceptions be addressed or corrected?\"\n",
    "\n",
    "history = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": message},\n",
    "]\n",
    "\n",
    "answer = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=history,\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    "    stream=False,  # Non-streaming\n",
    ")\n",
    "\n",
    "print(\"==== Round 1 ====\")\n",
    "print(\"==== Reasoning ====\")\n",
    "print(answer.choices[0].message.reasoning_content)\n",
    "print(\"==== Output ====\")\n",
    "print(answer.choices[0].message.content)\n",
    "\n",
    "history.append({\"role\": \"assistant\", \"content\": answer.choices[0].message.content})\n",
    "history.append({\"role\": \"user\", \"content\": message2})\n",
    "\n",
    "answer = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=history,\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    "    stream=False,  # Non-streaming\n",
    ")\n",
    "\n",
    "print(\"\\n\\n==== Round 2 ====\")\n",
    "print(\"==== Reasoning ====\")\n",
    "print(answer.choices[0].message.reasoning_content)\n",
    "print(\"==== Output ====\")\n",
    "print(answer.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('id', 'af599d44040345a19d280cc5e387a20d')\n",
      "('object', 'chat.completion')\n",
      "('created', 1742013267)\n",
      "('model', '')\n",
      "('choices', [{'index': 0, 'message': {'role': 'assistant', 'content': 'The capital of France is Paris. Paris serves as the political, economic, and cultural center of the country, housing government institutions, major businesses, universities, and significant cultural landmarks. It is where the President resides in the Elysée Palace and where the French Parliament is located. Additionally, Paris is home to many international organizations, further solidifying its status as the capital.', 'reasoning_content': 'Okay, so I need to figure out what the capital of France is. Hmm, I\\'ve heard people talk about Paris a lot, especially in the context of France. But I\\'m not 100% sure. Let me think about this. I remember learning about different countries and their capitals in school. I think Paris is a major city in France, known for landmarks like the Eiffel Tower and the Louvre Museum. But wait, is Paris really the capital? I don\\'t recall any other city being mentioned as the capital, but sometimes countries have multiple cities acting as administrative centers. \\n\\nWait, I also remember that some countries have their capitals not being the largest city. For example, Washington D.C. is the capital of the United States, but it\\'s not the largest city. But in the case of France, Paris is both the largest city and the capital, right? I think so. I\\'ve never heard of another city in France being called the capital. Maybe Lyon or Marseille? No, those are other big cities but not capitals. \\n\\nI should also consider if there\\'s any historical context where the capital might have been different. I know that during the Middle Ages, Paris was already an important city, but was it always the capital? I believe it has been the capital for a very long time, maybe even since the early modern period. \\n\\nAnother way to think about it is through language. The term \"capital\" usually refers to the seat of government. Paris is where the government buildings, like the Elysée Palace (where the President lives) and the French Parliament are located. So that makes sense. If I think about embassies and diplomatic missions, they are usually in the capital city. Paris is where foreign embassies would be located in France, which adds up to it being the capital. \\n\\nI also recall that France has regions and departments, but the administrative capital is Paris. Sometimes countries have their legislative bodies in different cities, but in France, both the executive and legislative branches are based in Paris. So that reinforces that Paris is indeed the capital. \\n\\nI think I\\'m pretty confident now that Paris is the capital of France. I don\\'t think I\\'m confusing it with any other country\\'s capital. For example, London is the capital of the UK, Berlin for Germany, Madrid for Spain. Paris fits the same pattern for France. \\n\\nMaybe to double-check, I can think of famous landmarks associated with Paris. The Eiffel Tower, the Champs-Élysées, the Arc de Triomphe, and the Louvre are all in Paris, which are iconic symbols of France. Capitals often have such landmarks because they\\'re centers of culture, politics, and economy. \\n\\nAlso, when I think about international organizations, many have headquarters in Paris, like UNESCO and the OECD. That further suggests that Paris is the center of important institutions, which is typical of a capital city. \\n\\nSo, putting it all together, Paris is the capital of France. It\\'s the political, economic, and cultural center of the country, housing government institutions, major businesses, universities, and cultural landmarks. I don\\'t think I\\'m missing any key points here. I can\\'t think of any other city in France that would serve as the capital, so I\\'m pretty certain that Paris is the correct answer.\\n', 'tool_calls': None}, 'logprobs': None, 'finish_reason': 'stop', 'matched_stop': 151643}])\n",
      "('usage', {'prompt_tokens': 12, 'total_tokens': 769, 'completion_tokens': 757, 'prompt_tokens_details': None})\n"
     ]
    }
   ],
   "source": [
    "%pip install requests\n",
    "\n",
    "import requests\n",
    "\n",
    "url = f\"http://{HOST}:{PORT}/v1/chat/completions\"\n",
    "headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "payload = {\n",
    "    \"model\": \"\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is the capital of France?\"}],\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "response_data = response.json()\n",
    "\n",
    "for i in response_data.items():\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
